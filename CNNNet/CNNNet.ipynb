{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Image Classifier\n",
    "\n",
    "2D convolutions produce outputs by applying filters, i. e. kernels, to 2D matrices. The outputs are 2D matrices as well. For detailed explanation visit: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1\n",
    "\n",
    "In PyTorch the Conv2d layer takes in the following parameters: `\n",
    "    nn.Conv2d(in_channels,out_channels, kernel_size, stride, padding)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `num_classes=2` parameter in `__init__` indicates how many classes the classifier outputs; as this is in fact the original AlexNet architecture the specification requiring classes to be stated thusly is met.\n",
    "\n",
    "`nn.Sequential()` allows creation of chains of layers, which enables breaking up of the model into more logical arrangements. Here two such chains are used: `features()` and `classifier()`.\n",
    "\n",
    "Pooling layers such as `MaxPool2d` are used to reduce the resolution of the network from previous input layer, which yields fewer parameters in lower layers. This compression speeds up computation and also prevents overfitting. For detailed explanation visit: https://analyticsindiamag.com/max-pooling-in-convolutional-neural-network-and-its-features/\n",
    "\n",
    "Alternative to `MaxPool` and `AvgPool` are `AdaptiveMaxPool` and `AdaptiveAvgPool` which work independently of the incoming tensor's dimensions and are for that reason recommended. Architectures using them can work with different input dimensions, which is handy when working with disparate datasets.\n",
    "\n",
    "`Dropout` layer is a simple way to prevent or reduce overfitting. It works by randomly selecting a certain user defined percent of the nodes which will not be updated during the training cycle. As a result, these nodes will be prevented from overfitting the data and the randomness helps increase this generalization further. Finally, `Dropout` layers are set in such manner that they are active only during training and not validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "                                                                    \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),  # input layer\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),           # layer\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),          # layer\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),          # layer\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),          # layer\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),                                           # layer\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),                                           # layer\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)                            # output layer\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnnet = CNNNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output, targets)\n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, TrainingLoss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'\n",
    "          .format(epoch, training_loss, valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "\n",
    "train_data_path = \"/Users/nikolavetnic/Desktop/Datasets/img_catfish/train/\"\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "    root=train_data_path,\n",
    "    transform=img_transforms,\n",
    "    is_valid_file=check_image)\n",
    "\n",
    "val_data_path = \"/Users/nikolavetnic/Desktop/Datasets/img_catfish/val/\"\n",
    "val_data = torchvision.datasets.ImageFolder(\n",
    "    root=val_data_path,\n",
    "    transform=img_transforms,\n",
    "    is_valid_file=check_image)\n",
    "\n",
    "test_data_path = \"/Users/nikolavetnic/Desktop/Datasets/img_catfish/test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "    root=test_data_path,\n",
    "    transform=img_transforms,\n",
    "    is_valid_file=check_image)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnnet.to(device)\n",
    "optimizer = optim.Adam(cnnnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolavetnic/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, TrainingLoss: 0.88, Validation Loss: 0.71, accuracy = 0.21\n",
      "Epoch: 1, TrainingLoss: 0.68, Validation Loss: 0.87, accuracy = 0.55\n",
      "Epoch: 2, TrainingLoss: 0.59, Validation Loss: 0.59, accuracy = 0.61\n",
      "Epoch: 3, TrainingLoss: 0.53, Validation Loss: 0.45, accuracy = 0.73\n",
      "Epoch: 4, TrainingLoss: 0.48, Validation Loss: 0.61, accuracy = 0.69\n",
      "Epoch: 5, TrainingLoss: 0.44, Validation Loss: 0.40, accuracy = 0.83\n",
      "Epoch: 6, TrainingLoss: 0.43, Validation Loss: 0.36, accuracy = 0.87\n",
      "Epoch: 7, TrainingLoss: 0.49, Validation Loss: 0.42, accuracy = 0.82\n",
      "Epoch: 8, TrainingLoss: 0.50, Validation Loss: 0.48, accuracy = 0.71\n",
      "Epoch: 9, TrainingLoss: 0.42, Validation Loss: 0.76, accuracy = 0.61\n"
     ]
    }
   ],
   "source": [
    "train(cnnnet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, val_data_loader, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had problems with making predictions code from the SimpleNet example, namely the final three lines. The problem was in wrong shape of the tensor `img` passed to the model, which is weird because it was of the same batch the model used to train on. This was resolved by performing `.unsqueeze(0)` on the tensor, which is a solution I found here: https://discuss.pytorch.org/t/runtimeerror-expected-4-dimensional-input-for-4-dimensional-weight-6-3-5-5-but-got-3-dimensional-input-of-size-3-256-256-instead/37189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    }
   ],
   "source": [
    "labels = ['cat', 'fish']\n",
    "\n",
    "img = Image.open(\"/Users/nikolavetnic/Desktop/Datasets/img_catfish/test/fish/246232021_a806f30fbc.jpg\")\n",
    "img = img_transforms(img).to(device)\n",
    "\n",
    "predicted_class = labels[torch.argmax(cnnnet(img.unsqueeze(0)))]\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
